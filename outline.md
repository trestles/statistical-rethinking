#### 1 The Golem of Prague
  - 1.1. Statistical Golems 1
    - Fig 1.1 Example Decision Tree 2
  - 1.2. Statistical Rethinking 4
    - Rethinking is NHST falsificationist? 5
    - 1.2.1. Hypotheses are not models 5
      - Rethinking Entropy and model identification 7
    - 1.2.2. Measurement matters 7
      - 1.2.2.1. Observation error 8
      - 1.2.2.2. Continuous hypothesis 9
    - 1.2.3. Falsification is consensual 9
  - 1.3. Three Tools for golem engineering 10
    - 1.3.1. Bayesian data analysis 10
      - Rethinking: Probability is not unitary 12
      - Rethinking: A little history 13
    - 1.3.2. Multilevel models 13
      - Rethinking: Multilevel election forecasting 15
    - 1.3.3. Model comparison and information criteria 15
      - Rethinking: The Neanderthal in you 16
  - 1.4. Summary 16

#### 2. Small Worlds and Large Worlds
  - Rethinking: Fast and frugal in the large world 20
  - 2.1. The Garden of Forking Data 20
    - 2.1.1. Counting possibilities 21
      - Rethinking: Justification 24
    - 2.1.2. Using prior information 25
      - Rethinking: Original ignorance 26
    - 2.1.3. From counts to probability 26
      - Rethinking: Randomization 28
  - 2.2. Building a model 28
    - 2.2.1. A data story 28
      - Rethinking: The value of storytelling 29
    - 2.2.2. Bayesian updating 29
      - Figure 2.5. How a Bayesian model learns 
      - Rethinking: Sample size and reliable inference 31
    - 2.2.3. Evaluate 31
      - Rethinking: Dictionary statistics 32
  - 2.3. Components of the model 32
    - 2.3.1. Likelihood 32
      - Overthinking: Names and probability distributions 33
      - Rethinking: A central role for likelihood 34
    - 2.3.2. Parameters 34
      - Rethinking: Datum or parameter? 34
    - 2.3.3. Prior 34
      - Overthinking: Prior as probability distribution 35
      - Rethinking: Prior, prior pants on fire 36
    - 2.3.4. Posterior 36
      - Rethinking: Bayesian data analysis isn't about Bayes' theorem! 37
  - 2.4. Making the model go 37
    - Figure 2.6 - The posterior distribution 38
    - Rethinking: How you fit the model is part of the model 39
    - 2.4.1. Grid approximation 39
      - Overthinking: Vectorization 40
    - 2.4.2. Quadratic approximation 41
      - Rethinking: Maximum likelihood estimation 44
      - Overthinking: The Hessians are coming 44
    - 2.4.3. Markov chain Monte Carlo
  - 2.5. Summary 45
  - 2.6. Practice 45

#### 3. Sampling the Imaginary 
  - Rethinking: The natural frequencey phenomenom is not unique 50
  - Rethinking: Why statistics can't save bad science 51
  - 3.1. Sampling from a grid-approximate posterior 52
    - Figure 3.1. Sampling parameter values from the posterior distribution 53
  - 3.2. Sampling to summarize 53
    - 3.2.1. Intervals of defined boundaries 53
    - 3.2.2. Overthinking: counting with sum 
      - Figure 3.2. Two kinds of posterior interval 55
      - Figure 3.3. The difference between percentile and highest posterior density confidence intervals 57
      - Rethinking: Why 95%? 58
      - Rethinking: What do confidence intervals mean? 58
    - 3.2.3. Point estimates 58
  - 3.3. Sampling to simulate prediction 61
    - 3.3.1. Dummy data 62
      - Rethinking: Sampling distributions 63
    - 3.3.2. Model Checking 64
      - 3.3.2.1. Did the software work? 64
      - 3.3.2.2. Is the model adequate? 64
        - Figure 3.6. Simulating predictions from the total posterior 66
        - Figure 3.7. Alternative views of the same posterior predictive distribution (see Fig 3.6) 67
        - Rethinking: What does more extreme mean? 
  - 3.4. Summary 68
  - 3.5. Practice 69

#### 4. Linear Models 
  - Figure 4.1. The Ptolemaic Universe 72
  - 4.1. Why normal distributions are normal? 72
    - 4.1.1. Normal by addition 72
    - 4.1.2. Normal by multiplication 74
    - 4.1.3. Normal by log-multiplication 75
    - 4.1.4. Using Guassian distributions 75
      - 4.1.4.1. Ontological justification 75
      - 4.1.4.2. Epistemological justification 75
      - Overthinking: Guassian distribution 76
  - 4.2. A language for describing models 77
    - 4.2.1. Re-describing the globe tossing model 78
    - Overthinking: From model definition to Bayes' theorem 78
  - 4.3. A Guassian model of height 78
    - 4.3.1. The data 79
      - Overthinking: Data frames 80
      - Overthinking: Index magic 80
    - 4.3.2. The model 80
      - Rethinking: Independent and identically distributed 81
      - Rethinking: A farewell to epsilon 83
      - Overthinking: Model definition to Bayes' theorem again 83
    - 4.3.3. Grid approximation of the posterior distribution 83
    - 4.3.4. Sampling from the posterior 84
      - Overthinking: Sample size and the normality of sigma's posterior 85
    - 4.3.5. Fitting the model with `map` 86
      - Overthinking: Start values for `map` 88
      - Overthinking: How strong is a prior? 89
    - 4.3.6. Sampling from a `map` fit 89
      - Overthinking: Under the hood with multivariate sampling 91
      - Overthinking: Getting sigma right 91
  - 4.4. Adding a predictor 82
    - Rethinking: What is regression? 92
    - 4.4.1. The linear model strategy 92
      - 4.4.1.1. Likelihood 93
      - 4.4.1.2. Linear model 93
        - Rethinking: Nothing special or natural about linear models 94
        - Overthinking: Units and regression models 94
      - 4.4.1.3. Priors 94
        - Rethinking: What's the correct prior? 95
      - 4.4.2. Fitting the model 95
        - Rethinking: Everything that depends on parameters has a posterior distribution 96
        - Overthinking: Embedding linear models 97
      - 4.4.3. Interpreting the model fit 97
        - Rethinking: What do parameters mean? 98
        - 4.4.3.1. Tables of estimates 98
        - 4.4.3.2. Plotting posterior inference against the data 100
        - 4.4.3.3. Adding uncertainty around the mean 100
        - 4.4.3.4. Plotting regression intervals and contours 102
          - Rethinking: Overconfident confidence intervals 107
          - Overthinking: How `link` works 107
        - 4.4.3.5. Prediction intervals 107 
          - Rethinking: Two kinds of uncertainty 109
          - Rethinking: Rolling your own `sim`
  - 4.5. Polynomial regression 110
    - Rethinking: Linear, addiditve, funky 111
    - Figure 4.9 Polynomial regressions of height on weight (standardized), for the ful !Kung data 113
    - Overthinking: Converting back to natural scale 114
  - 4.6. Summary 115
  - 4.7. Practice 115

#### 5. Multivariate Linear Models 119
  - Figure 5.1 The number of Waffle House diners per million people is associated with divorce rate (in the year 2009) within the United States 120
  - Firgure 5.2 Divorce rate is associated with both marriage rate (left) and median age at marriage (right). Both predictor variables are standardized in this example. The average marraige rate across States is 20 per 1000 adults and the average median age at marriage is 26 years.  121
  - 5.1. Spurious association 121
    - Rethinking: "Control" is out of control 123
    - 5.1.1. Multivariate notation 123
      - Overthinking: Compact notation and the design matrix 124
    - 5.1.2. Fitting the model 125
    - 5.1.3 Plotting multivariate posteriors 126
      - Figure 5.3 Residual marriage rate in each State, after accounting for linear association with median age at marriage 127
      - 5.1.3.1 Predictor residual plots 126
      - Figure 5.4 Predictor residual plots for the divorce data 128
      - 5.1.3.2 Counterfactual plots 129
      - 5.1.3.3 Posterior prediction plots 131
      - Figure 5.6 Posterior predictive plots for the multivariate divorce model 133
      - Rethinking: Stats, huh, what is it good for? 134
      - Overthinking: Simulating spurious association 
  - 5.2. Masked relationship 135
    - Figure 5.7 Milk energy and neocortex among primates 138
    - Overthinking: Simulating a masking relationship 141
  - 5.3. When adding variables hurts 141
    - 5.3.1 Multicolinear legs 142
    - Figure 5.8 Left: Posterior distribution of the association of each leg with height, from model m5.8 p144
    - Figure 5.9 A pairs plot of the total energy, percent fat, and percent lactose variables from the primate milk data. p147
    - Figure 5.10 The effect of correlated predictor variables on the narrowness of the posterior distribution 149
    - Rethinking: Identification guaranteed; comprehension up to you
    - Overthinking: Simulating Collineararity 
    - 5.3.3 Post-treatment bias 150
      - Rethinking: Model comparison doesn't help 152
  - 5.4. Categorical variables 152
    - 5.4.1 Binary categories 153
      - Overthinking: Re-parameterizing the model 154
    - 5.4.2 Many Categories 155
      - Rethinking: Differences in statistical significance 157
    - 5.4.3 Adding regular predictor variables 158
    - 5.4.4 Another approach: Unique intercepts 158
  - 5.5. Ordinary least squares and `lm` 159
    - 5.5.1. Design formulas 159
    - 5.5.2. Using `lm`
      - 5.5.2.1. Intercepts are optional 160
      - 5.5.2.2. Categorical variables 160
      - 5.5.2.3. Transform variables first 161
      - 5.5.2.4. No estimate for sigma 161
    - 5.5.3. Building `map` formulas from `lm` formulas 161
  - 5.6. Summary 162
  - 5.7. Practice 162

#### 6 Overfitting, Regularization, and Information Criteria
  - Rethinking: Stargazing 167
  - Rethinking: Is AIC Bayesian? 167
  - 6.1. The problem with parameters 167
    - Figure 6.2. Average brain volume in cubic centimeters against body mass in kilograms, for six hominin species. What model best describes the relationship between brain size and body size? p168
    - 6.1.1. More parameters always improve fit / Overfitting 168
      - Figure 6.3. Polynomial models of increasing degree, fit to the hominim data 171
      - Figure 6.4. An underfit model of hominin brain volume. This model ignores any association between body mass and brain volume, producing a horizontal line of predictions. As a result, the model fits badly and (presumably) predicts badly p172
      - Rethinking: Model fitting as compression p172
    - 6.1.2. Too few parameters hurts too p172
      - Figure 6.5. Underfitting and overfitting as under-sensitivity and over-sensitivity so sample p173
      - Overthinking: dropping rows p174
      - Rethinking: Bias and variance p174
  - 6.2. Information theory and model performance 174
    - 6.2.1. Firing the weatherperson 174
      - 6.2.1.1. Costs and benefits 175
      - 6.2.1.2. Measuring accuracy 176
      - Rethinking: What is a true model? p176
    - 6.2.2. Information and uncertainty 177
      - Overthinking: More on entropy 178
      - Rethinking: The benefits of maximizing uncertainty 179
    - 6.2.3. From entropy to accuracy 179
      - Overthinking: Cross entropy and divergence 180
      - Rethinking: Divergence depends upon direction 180
    - 6.2.4. From divergence to deviance 
      - Overthinking: Computing deviance p182
    - 6.2.5. From deviance to out-of-sample p183
      - Figure 6.7. Deviance in and out of sample p184
      - Overthinking: Simulated training and testing p185
  - 6.3. Regularization 186
    - Figure 6.8 Regularizing priors, weak and strong. Three guassian priors of varying standard deviation. These priors reduce overfitting, but with different strength. Dashed:Normal (0,1). Thin solid: Normal(0, 0.5). Thick Solid: Normal (0, 0.2) 187
    - Figure 6.9 Regularizing priors and out-of-sample deviance p188
    - Rethinking: Multilevel models as adaptive regularization p188
    - Rethinking: Ridge Regression p188
  - 6.4. Information criteria 188
    - Rethinking: Information criteria and consistency 190
    - 6.4.1. DIC p190
    - 6.4.2. WAIC p191
      - Reathinking: What about BIC? 192
      - Ovethinking: WAIC calculations 192
        - figure 6.11 Out-of-sample deviance as estimated by DIC and WAIC p194
    - 6.4.3. DIC and WAIC as estimates of deviance p194
      - Rethinking: Diverse prediction frameworks p194
  - 6.5. Using information criteria 195
    - 6.5.1. Model comparison p196
      - 6.5.1.1. Comparing WAIC values p197
        - Rethinking: How big a difference in WAIC is "significant"? p200
        - Rethinking: WAIC Metaphors p201
      - 6.5.1.2. Comparing estimates p201
        - Rethinking: Barplots suck p203
    - 6.5.2. Model averaging p203
      - Figure 6.13 Model averaged posterior predictive distribution for the primate milk analysis p204
      - Rethinking: The Curse of Tippecanoe p204
  - 6.6. Summary p205
  - 6.7. Practice p205


  #### 7 Interactions
  - 7.1. Building an Interaction p211
  - 7.2. Symmetry of the linear interaction p223
  - 7.3. Continuous interactions p225
  - 7.4. Interactions in design formulas p235
  - 7.5. Summary p236
  - 7.6. Practice pp236

  #### 8. Markov Chain Monte Carlo p241
  - 8.1. Good King Markov and His Island Kingdom p242
  - 8.2. Markov Chain Monte Carlo p245
  - 8.3. Easy HMC: map2stan p247
  - 8.4. Care and feeding of your Markov chain p255
  - 8.5. Summary p263
  - 8.6. Practice p263

  #### 9 Big Entropy and the Generalized Linear Model p267
  - 9.1. Maximum entropy p268
  - 9.2. Generalized linear models p280
  - 9.3. Maximum entropy priors p288
  - 9.4. Summary p289

#### 10. Counting and Classification p291
- 10.1. Binomial regression p292
- 10.2. Poisson regression p311
- 10.3. Other count regressions p322
- 10.4. Summary p328
- 10.5. Practice p329

#### 11. Monsters and Mixtures p331
- 11.1. Ordered categorical outcomes p331
- 11.2. Zero-inflated outcomes p342
- 11.3. Over-dispersed outcomes p346
- 11.4. Summary p351
- 11.5. Practice p352

#### 12. Multilevel Models p355
- 12.1 Example: 12.1. Multilevel tadpoles p357
- 12.2. Varying effects and the underfitting / overfitting tradeoff p364
- 12.3. More than one type of cluster p370
- 12.4. Multilevel posterior predictions p376
- 12.5. Summary p384
- 12.6. Practice p384

#### 13. Adventures in Covariance p387
- 13.1. Varying slopes by construction p389
- 13.2. Example: Admission decisons and gender p398
- 13.3. Example: Cross-classified chimpanzees with varying slopes p403


